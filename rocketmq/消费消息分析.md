---
categories:
  - rocketmq
date: 2017-05-08 16:20
status: public
tags:
  - rocketmq
  - 分布式
title: 'RocketMQ 消费消息分析'
---

消费消息涉及到三个角色，nameserver，broker，consumer。首先consumer从nameserver中拿到topic的queue的分布，然后从broker中拿到该topic和这个consumer相同group的consumer列表，做sharding，确定balance即当前的consumer需要消费的queue是哪几个，然后异步从这些queue中拉取消息消费。在拉取到消息后会同步消费位点到broker中。

![](http://processon.com/chart_image/5a9a10ede4b0a9d22eb1db41.png)

### 一、获取订阅topic的queue列表
获取订阅topic的路由信息，转换为queue列表

```java
public Set<MessageQueue> fetchSubscribeMessageQueues(String topic) throws MQClientException {
    Set<MessageQueue> result = this.rebalanceImpl.getTopicSubscribeInfoTable().get(topic);
    if (null == result) {
        this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic);
        result = this.rebalanceImpl.getTopicSubscribeInfoTable().get(topic);
    }

    if (null == result) {
        throw new MQClientException("The topic[" + topic + "] not exist", null);
    }

    return result;
}
```

从nameserver获取的routeinfo如下,具体转换为topic的细节请看消息发送的文档，里面有介绍

```java
private String orderTopicConf;
private List<QueueData> queueDatas;
private List<BrokerData> brokerDatas;
private HashMap<String/* brokerAddr */, List<String>/* Filter Server */> filterServerTable;
```

### 二、Sharding queue
先获取Cid列表

```java
Set<MessageQueue> mqSet = this.topicSubscribeInfoTable.get(topic);
List<String> cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup);
```
分配 queue到consumer中,得到当前consumer的queue列表

```java
AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy;

List<MessageQueue> allocateResult = null;
try {
    allocateResult = strategy.allocate(//
        this.consumerGroup, //
        this.mQClientFactory.getClientId(), //
        mqAll, //
        cidAll);
} catch (Throwable e) {
    log.error("[Allocate] Exception. allocateQueueStrategyName={}", strategy.getName(), e);
    return;
}
```

### 三、拉取订阅的topic queue的offset
拉取订阅的queue的offset如果是广播模式，则从本地文件系统拉取，如果是集群模式，则从remote拉取。remote是从broker中拉取，在生成request的时候如果localcache里面没有这个queue的offset，会从broker去获取。

```java
@Override
public long readOffset(final MessageQueue mq, final ReadOffsetType type) {
    if (mq != null) {
        switch (type) {
            case MEMORY_FIRST_THEN_STORE:
            case READ_FROM_MEMORY: {
                AtomicLong offset = this.offsetTable.get(mq);
                if (offset != null) {
                    return offset.get();
                } else if (ReadOffsetType.READ_FROM_MEMORY == type) {
                    return -1;
                }
            }
            case READ_FROM_STORE: {
                try {
                    long brokerOffset = this.fetchConsumeOffsetFromBroker(mq);
                    AtomicLong offset = new AtomicLong(brokerOffset);
                    this.updateOffset(mq, offset.get(), false);
                    return brokerOffset;
                }
                // No offset in broker
                catch (MQBrokerException e) {
                    return -1;
                }
                //Other exceptions
                catch (Exception e) {
                    log.warn("fetchConsumeOffsetFromBroker exception, " + mq, e);
                    return -2;
                }
            }
            default:
                break;
        }
    }

    return -1;
}
```

### 三、开始pull消息
检查当前分配到的queue和之前的queue有没有变化，如果有变化，更新本地缓存，提交pull任务

```java
Set<MessageQueue> allocateResultSet = new HashSet<MessageQueue>();
if (allocateResult != null) {
    allocateResultSet.addAll(allocateResult);
}

boolean changed = this.updateProcessQueueTableInRebalance(topic, allocateResultSet, isOrder);
if (changed) {
    log.info(
        "rebalanced result changed. allocateMessageQueueStrategyName={}, group={}, topic={}, clientId={}, mqAllSize={}, cidAllSize={}, rebalanceResultSize={}, rebalanceResultSet={}",
        strategy.getName(), consumerGroup, topic, this.mQClientFactory.getClientId(), mqSet.size(), cidAll.size(),
        allocateResultSet.size(), allocateResultSet);
    this.messageQueueChanged(topic, mqSet, allocateResultSet);
}

updateProcessQueueTableInRebalance（...）{
### 1更新本地缓存
### 2 生成requests
### dispatch request 生成request queue的方式是之前这个queue没有在process中，如果之前已经拉取过，不会再生成，避免资源浪费
this.dispatchPullRequest(pullRequestList);
}

```
对于提交pull任务，如果是pullconsumer，则啥都不做，仅更新分配给当前consumer的queue列表，即this.dispatchPullRequest在pull中什么都不做。如果是push任务，则会启动异步去拉取消息，在this.dispatchPullRequest中提交拉取消息task。

### 四、处理consumer加入与退出
有个ReblanceService后台异步线程在跑，过一段时间reblance一次，reblance会不断获取consumer id的列表，来更新属于当前节点的queue列表来达到感知consumer的新加入与退出。

```java
public void doRebalance() {
    for (Map.Entry<String, MQConsumerInner> entry : this.consumerTable.entrySet()) {
        MQConsumerInner impl = entry.getValue();
        if (impl != null) {
            try {
                impl.doRebalance();
            } catch (Throwable e) {
                log.error("doRebalance exception", e);
            }
        }
    }
}
//实际上调用的事rebalanceImpl来做的，如下
public void doRebalance(final boolean isOrder) {
    Map<String, SubscriptionData> subTable = this.getSubscriptionInner();
    if (subTable != null) {
        for (final Map.Entry<String, SubscriptionData> entry : subTable.entrySet()) {
            final String topic = entry.getKey();
            try {
                this.rebalanceByTopic(topic, isOrder);
            } catch (Throwable e) {
                if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
                    log.warn("rebalanceByTopic Exception", e);
                }
            }
        }
    }

    this.truncateMessageQueueNotMyTopic();
}
```
reblance里面会做sharding更新，重复第二步的操作